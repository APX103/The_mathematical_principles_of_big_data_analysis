# 第四讲 中心极限定理的应用



> 本讲主要讲解中心极限定理以及如何应用它解决问题



## 中心极限定理

**<u>中心极限定理</u>**  是指概率论中讨论随机变量序列部分和分布渐近于正态分布的一类定理。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量近似服从正态分布的条件。它是概率论中最重要的一类定理，有广泛的实际应用背景。在自然界与生产中，一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。中心极限定理就是从数学上证明了这一现象。最早的中心极限定理是讨论重点，伯努利试验中，事件A出现的次数渐近于正态分布的问题。



> 伯努利试验（Bernoulli experiment）是在同样的条件下重复地、相互独立地进行的一种随机试验，其特点是该随机试验只有两种可能结果：发生或者不发生。我们假设该项试验独立重复地进行了n次，那么就称这一系列重复独立的随机试验为n重伯努利试验，或称为伯努利概型。单个伯努利试验是没有多大意义的，然而，当我们反复进行伯努利试验，去观察这些试验有多少是成功的，多少是失败的，事情就变得有意义了，这些累计记录包含了很多潜在的非常有用的信息。



- 一个随机变量不管是连续分布还是离散分布，在取了平均值以后他的分布都符合**正态分布**
- 标准化以后则符合标准正态分布
- **条件是数据量足够大**



# 用中心极限定理估计

### 扔10000次硬币平均值的误差

- 正面出现4900次，可信度有多大?

- 平均值应该是μ =0.5,现在为0.49，0.49-0.5 =-0.01

- 假定正态分布,标准差为σ=0.5/100 = 0.005

- 离平均值两个σ，查表得0.028, 可信度在5%之内。

### 假如三个σ，可信度只有千分之3之内

- n多大才可以用正态分布?
- 一般收敛速度大概是~ n的-1/2次方



## 数据造假

> 如何发现数据造假行为

- 随机数据有规律,而造假往往破坏了内在规律
- **数据越大，规律越强**
- 大量数据分组以后，每组都有同样的规律
- 大数据分析常用方法是预留部分数据作为验证数据,对训练数据的结果进行验证
- 实验室的数据一般可以假定为正态分布，精度(有效数字)决定了标准差。在有效数字之外基本可以认为是随机的
- 在数字量不大的情况下，可以考虑二进制(奇数、偶数...) ，更有统计意义



## 习题

1. 一篇学术论文有500个数据 ,每个数据精确到6位，而有效数字为3位。倒数第二位数字偶数有230 ,奇数有270。你觉得可信吗?估计一下可信度有多少。
2. 传染病估计（第一讲留下的问题）
   - 3万份问卷里有1万2千人回答有传染病,真实比例估计是多少?算一下误差会有多大?
   - 30万份问卷里有12万人回答有传染病,真实比例应该是多少?算一下误差会有多大?
3. 圆周率π的随机性
   - 在网上找出圆周率π精确到100万位的数值。用四位数表示你出生的月日，你的生日在π出现过多少次?
   - 如果π中每个数字的出现是随机的,你的生日应该出现多少次?
   - 随机取一个三位数,在r里出现多少次?



## 结论

- 随机数据有规律，数据越大规律越强，结果越可靠!
- 大数据分析就是要找出数据规律。